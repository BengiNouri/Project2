{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/BengiNouri/Project2/blob/main/segment_ml_el.ipynb",
      "authorship_tag": "ABX9TyM6/4yAa04Ql/GMAMU2JcCj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BengiNouri/Project2/blob/main/clean_ml_el.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaiG06CWtQlR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/new_car_data_el123.csv')"
      ],
      "metadata": {
        "id": "jjiOdB32toRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_replace = ['GPS','Range (Electric)','Trailer Hitch', '4WD', 'Parkingsensor', 'Cruise Control', 'Antispin', 'ESP', 'El-SÃ¦der', 'Leather Interior', 'Glass Roof', 'Headup Display', 'Isofix', 'KlimaanlÃ¦g', 'Regnsensor', 'Soltag', 'Sports Package', 'Seatwarmer', 'Xenon Lights', 'Non-Smoker', 'One-Owner', 'Service OK', 'Nysynet', 'Demo Car', 'Partly Leather Interior', 'CVR/Engros', 'Full Leather', 'Adaptive Cruise Control']  # Specify the columns you want to replace values in\n",
        "data[columns_to_replace] = data[columns_to_replace].replace({'Yes': 1, 'No': 0})"
      ],
      "metadata": {
        "id": "zzlveml03z24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make vector of features for modelling\n",
        "selected_features = data.columns.tolist()\n",
        "# Remove the columns from our vector that are not meant to be used for modelling\n",
        "selected_features.remove('Price')\n",
        "selected_features.remove('Link')\n",
        "selected_features.remove('Segment')\n"
      ],
      "metadata": {
        "id": "VnuxNDAtzKic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_data = data[data['Segment'] == 'Premium']\n",
        "\n",
        "\n",
        "# Perform the train-test split on the Premium segment\n",
        "pX_train, pX_test, py_train, py_test = train_test_split(\n",
        "    p_data[selected_features],\n",
        "    p_data['Price'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "Hz9q8bABJZqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN Model\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(pX_train)\n",
        "X_test_scaled = scaler.transform(pX_test)\n",
        "\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "knn.fit(X_train_scaled, py_train)\n",
        "\n",
        "predictions = knn.predict(X_test_scaled)\n",
        "r_squared = r2_score(py_test, predictions)\n",
        "mae = mean_absolute_error(py_test, predictions)\n",
        "rmse = np.sqrt(mean_squared_error(py_test, predictions))\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"R² Score: {r_squared}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")"
      ],
      "metadata": {
        "id": "xZtEM8HdymLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline xgboosting without parameters # 6 sec\n",
        "xgb_model = XGBRegressor(n_estimators=600)\n",
        "xgb_model.fit(pX_train, py_train)\n",
        "predictions_xgb = xgb_model.predict(pX_test)\n",
        "\n",
        "#Metrics\n",
        "r_squared = r2_score(py_test, predictions_xgb)\n",
        "mae = mean_absolute_error(py_test, predictions_xgb)\n",
        "mse = mean_squared_error(py_test, predictions_xgb)\n",
        "rmse = np.sqrt(mse)\n",
        "#Print Metrics\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = xgb_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': pX_train.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "N = 25  # Number of Features\n",
        "print(\"Top\", N, \"important features:\")\n",
        "print(feature_importance_df.head(N))"
      ],
      "metadata": {
        "id": "Ym3QlTxqzcfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoosting with hyperparameters # 32 min\n",
        "\n",
        "# Defining grid\n",
        "param_grid = {\n",
        "        'min_child_weight': [5, 10],\n",
        "        'gamma': [0, 2],\n",
        "        'subsample': [0.6, 1.0],\n",
        "        'colsample_bytree': [0.6, 1.0],\n",
        "        'max_depth': [3, 8, 12]\n",
        "        }\n",
        "\n",
        "xgb_model = XGBRegressor(n_estimators=600)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=0)\n",
        "grid_search.fit(pX_train, py_train)\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "predictions = best_model.predict(pX_test)\n",
        "\n",
        "#Metrics\n",
        "r_squared = r2_score(py_test, predictions)\n",
        "mae = mean_absolute_error(py_test, predictions)\n",
        "mse = mean_squared_error(py_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "#Print Metrics\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = best_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': pX_train.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "N = 25  # Number of Features\n",
        "print(\"Top\", N, \"important features:\")\n",
        "print(feature_importance_df.head(N))"
      ],
      "metadata": {
        "id": "wYWHc4mEz7AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest # 2 min\n",
        "rf_model = RandomForestRegressor(n_estimators=600, random_state=42)\n",
        "\n",
        "\n",
        "rf_model.fit(pX_train, py_train)\n",
        "rpredictions = rf_model.predict(pX_test)\n",
        "\n",
        "# Metrics\n",
        "rr_squared = r2_score(py_test, rpredictions)\n",
        "rmae = mean_absolute_error(py_test, rpredictions)\n",
        "rmse = mean_squared_error(py_test, rpredictions)\n",
        "rrmse = np.sqrt(rmse)\n",
        "\n",
        "print(\"Random Forest Regression Model Evaluation:\")\n",
        "print(\"R-squared:\", rr_squared)\n",
        "print(\"Mean Absolute Error:\", rmae)\n",
        "print(\"Mean Squared Error:\", rmse)\n",
        "print(\"Root Mean Squared Error:\", rrmse)\n",
        "\n",
        "# Feature Importance For Random Forest\n",
        "feature_importances = rf_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': pX_train.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "N = 25  # Number of Features\n",
        "print(\"Top\", N, \"important features:\")\n",
        "print(feature_importance_df.head(N))\n",
        "\n",
        "tree = rf_model.estimators_[0]\n",
        "\n",
        "# Plot the tree\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(tree, filled=True, feature_names=pX_train.columns, max_depth=3, precision=2, proportion=True)\n",
        "plt.title('Decision Tree from Random Forest')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cPeMDsp-FwaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear regressionsmodel # 1 sec\n",
        "l_features = ['KM Driven', 'Year', 'Horsepower', 'Km/L', 'Brand_Mercedes', 'Range (Electric)']\n",
        "lX_train, lX_test, ly_train, ly_test = train_test_split(p_data[l_features], p_data['Price'], test_size=0.2, random_state=42)\n",
        "\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "linear_model.fit(lX_train, ly_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "linear_predictions = linear_model.predict(lX_test)\n",
        "\n",
        "# Metrics\n",
        "linear_r_squared = r2_score(ly_test, linear_predictions)\n",
        "linear_mae = mean_absolute_error(ly_test, linear_predictions)\n",
        "linear_mse = mean_squared_error(ly_test, linear_predictions)\n",
        "linear_rmse = np.sqrt(linear_mse)\n",
        "\n",
        "print(\"Linear Regression Model Evaluation:\")\n",
        "print(\"R-squared:\", linear_r_squared)\n",
        "print(\"Mean Absolute Error:\", linear_mae)\n",
        "print(\"Mean Squared Error:\", linear_mse)\n",
        "print(\"Root Mean Squared Error:\", linear_rmse)"
      ],
      "metadata": {
        "id": "3pOpTvZm095r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_data = data[data['Segment'] == 'Mid-Range']\n",
        "\n",
        "\n",
        "# Perform the train-test split on the Mid-Range segment\n",
        "mX_train, mX_test, my_train, my_test = train_test_split(\n",
        "    m_data[selected_features],\n",
        "    m_data['Price'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "HHQhpSX4ZrCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN Model\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(mX_train)\n",
        "X_test_scaled = scaler.transform(mX_test)\n",
        "\n",
        "knn = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors\n",
        "knn.fit(X_train_scaled, my_train)\n",
        "\n",
        "predictions = knn.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "r_squared = r2_score(my_test, predictions)\n",
        "mae = mean_absolute_error(my_test, predictions)\n",
        "rmse = np.sqrt(mean_squared_error(my_test, predictions))\n",
        "\n",
        "# Print the performance metrics\n",
        "print(f\"R² Score: {r_squared}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")"
      ],
      "metadata": {
        "id": "NgZy4x3jzJep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline xgboosting without parameters # 6 sec\n",
        "xgb_model = XGBRegressor(n_estimators=600)\n",
        "xgb_model.fit(mX_train, my_train)\n",
        "predictions_xgb = xgb_model.predict(mX_test)\n",
        "\n",
        "#Metrics\n",
        "r_squared = r2_score(my_test, predictions_xgb)\n",
        "mae = mean_absolute_error(my_test, predictions_xgb)\n",
        "mse = mean_squared_error(my_test, predictions_xgb)\n",
        "rmse = np.sqrt(mse)\n",
        "#Print Metrics\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = xgb_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': mX_train.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "N = 25  # Number of Features\n",
        "print(\"Top\", N, \"important features:\")\n",
        "print(feature_importance_df.head(N))"
      ],
      "metadata": {
        "id": "QFs-q9pWZyrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoosting with hyperparameters # 32 min\n",
        "\n",
        "# Defining grid\n",
        "param_grid = {\n",
        "        'min_child_weight': [5, 10],\n",
        "        'gamma': [0, 2],\n",
        "        'subsample': [0.6, 1.0],\n",
        "        'colsample_bytree': [0.6, 1.0],\n",
        "        'max_depth': [3, 8, 12]\n",
        "        }\n",
        "\n",
        "xgb_model = XGBRegressor(n_estimators=600)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=0)\n",
        "grid_search.fit(mX_train, my_train)\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "predictions = best_model.predict(mX_test)\n",
        "\n",
        "#Metrics\n",
        "r_squared = r2_score(my_test, predictions)\n",
        "mae = mean_absolute_error(my_test, predictions)\n",
        "mse = mean_squared_error(my_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "#Print Metrics\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = best_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': mX_train.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "N = 25  # Number of Features\n",
        "print(\"Top\", N, \"important features:\")\n",
        "print(feature_importance_df.head(N))"
      ],
      "metadata": {
        "id": "Wr4rbG7UZ00d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest # 2 min\n",
        "rf_model = RandomForestRegressor(n_estimators=600, random_state=42)\n",
        "\n",
        "\n",
        "rf_model.fit(mX_train, my_train)\n",
        "\n",
        "rpredictions = rf_model.predict(mX_test)\n",
        "\n",
        "# Metrics\n",
        "rr_squared = r2_score(my_test, rpredictions)\n",
        "rmae = mean_absolute_error(my_test, rpredictions)\n",
        "rmse = mean_squared_error(my_test, rpredictions)\n",
        "rrmse = np.sqrt(rmse)\n",
        "\n",
        "print(\"Random Forest Regression Model Evaluation:\")\n",
        "print(\"R-squared:\", rr_squared)\n",
        "print(\"Mean Absolute Error:\", rmae)\n",
        "print(\"Mean Squared Error:\", rmse)\n",
        "print(\"Root Mean Squared Error:\", rrmse)\n",
        "\n",
        "# Feature Importance For Random Forest\n",
        "feature_importances = rf_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': mX_train.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "N = 25  # Number of Features\n",
        "print(\"Top\", N, \"important features:\")\n",
        "print(feature_importance_df.head(N))\n",
        "\n",
        "tree = rf_model.estimators_[0]\n",
        "\n",
        "# Plot the tree\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(tree, filled=True, feature_names=mX_train.columns, max_depth=3, precision=2, proportion=True)\n",
        "plt.title('Decision Tree from Random Forest')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aAf2sD6qZ3hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear regressionsmodel # 1 sec\n",
        "l_features = ['KM Driven', 'Year', 'Horsepower', 'Km/L', 'Gear_Automatgear', 'Range (Electric)', 'Adaptive Cruise Control']\n",
        "lX_train, lX_test, ly_train, ly_test = train_test_split(m_data[l_features], m_data['Price'], test_size=0.2, random_state=42)\n",
        "\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "linear_model.fit(lX_train, ly_train)\n",
        "\n",
        "linear_predictions = linear_model.predict(lX_test)\n",
        "\n",
        "# Metrics\n",
        "linear_r_squared = r2_score(ly_test, linear_predictions)\n",
        "linear_mae = mean_absolute_error(ly_test, linear_predictions)\n",
        "linear_mse = mean_squared_error(ly_test, linear_predictions)\n",
        "linear_rmse = np.sqrt(linear_mse)\n",
        "\n",
        "print(\"Linear Regression Model Evaluation:\")\n",
        "print(\"R-squared:\", linear_r_squared)\n",
        "print(\"Mean Absolute Error:\", linear_mae)\n",
        "print(\"Mean Squared Error:\", linear_mse)\n",
        "print(\"Root Mean Squared Error:\", linear_rmse)"
      ],
      "metadata": {
        "id": "EtX4zFO4Z7QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e_data = data[data['Segment'] == 'Economy']\n",
        "\n",
        "\n",
        "# Perform the train-test split on the Economy segment\n",
        "eX_train, eX_test, ey_train, ey_test = train_test_split(\n",
        "    e_data[selected_features],\n",
        "    e_data['Price'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "dqecwKX2a_41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN Model\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(eX_train)\n",
        "X_test_scaled = scaler.transform(eX_test)\n",
        "\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "knn.fit(X_train_scaled, ey_train)\n",
        "\n",
        "predictions = knn.predict(X_test_scaled)\n",
        "\n",
        "# Metrics\n",
        "r_squared = r2_score(ey_test, predictions)\n",
        "mae = mean_absolute_error(ey_test, predictions)\n",
        "rmse = np.sqrt(mean_squared_error(ey_test, predictions))\n",
        "\n",
        "# Print the performance metrics\n",
        "print(f\"R² Score: {r_squared}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")"
      ],
      "metadata": {
        "id": "xayC_BLyzVgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline xgboosting without parameters # 6 sec\n",
        "xgb_model = XGBRegressor(n_estimators=600)\n",
        "xgb_model.fit(eX_train, ey_train)\n",
        "predictions_xgb = xgb_model.predict(eX_test)\n",
        "\n",
        "#Metrics\n",
        "r_squared = r2_score(ey_test, predictions_xgb)\n",
        "mae = mean_absolute_error(ey_test, predictions_xgb)\n",
        "mse = mean_squared_error(ey_test, predictions_xgb)\n",
        "rmse = np.sqrt(mse)\n",
        "#Print Metrics\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = xgb_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': eX_train.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "N = 25\n",
        "print(\"Top\", N, \"important features:\")\n",
        "print(feature_importance_df.head(N))"
      ],
      "metadata": {
        "id": "AKjJXTIQbLnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoosting with hyperparameters # 32 min\n",
        "\n",
        "# Defining grid\n",
        "param_grid = {\n",
        "        'min_child_weight': [5, 10],\n",
        "        'gamma': [0, 2],\n",
        "        'subsample': [0.6, 1.0],\n",
        "        'colsample_bytree': [0.6, 1.0],\n",
        "        'max_depth': [3, 8, 12]\n",
        "        }\n",
        "\n",
        "xgb_model = XGBRegressor(n_estimators=600)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=0)\n",
        "grid_search.fit(eX_train, ey_train)\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "predictions = best_model.predict(eX_test)\n",
        "\n",
        "#Metrics\n",
        "r_squared = r2_score(ey_test, predictions)\n",
        "mae = mean_absolute_error(ey_test, predictions)\n",
        "mse = mean_squared_error(ey_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "#Print Metrics\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = best_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': eX_train.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "N = 25  # Number of Features\n",
        "print(\"Top\", N, \"important features:\")\n",
        "print(feature_importance_df.head(N))"
      ],
      "metadata": {
        "id": "JSja_jtMbP8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest # 2 min\n",
        "rf_model = RandomForestRegressor(n_estimators=600, random_state=42)\n",
        "\n",
        "\n",
        "rf_model.fit(eX_train, ey_train)\n",
        "rpredictions = rf_model.predict(eX_test)\n",
        "\n",
        "# Metrics\n",
        "rr_squared = r2_score(ey_test, rpredictions)\n",
        "rmae = mean_absolute_error(ey_test, rpredictions)\n",
        "rmse = mean_squared_error(ey_test, rpredictions)\n",
        "rrmse = np.sqrt(rmse)\n",
        "\n",
        "print(\"Random Forest Regression Model Evaluation:\")\n",
        "print(\"R-squared:\", rr_squared)\n",
        "print(\"Mean Absolute Error:\", rmae)\n",
        "print(\"Mean Squared Error:\", rmse)\n",
        "print(\"Root Mean Squared Error:\", rrmse)\n",
        "\n",
        "# Feature Importance For Random Forest\n",
        "feature_importances = rf_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': eX_train.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "N = 25  # Number of Features\n",
        "print(\"Top\", N, \"important features:\")\n",
        "print(feature_importance_df.head(N))\n",
        "\n",
        "tree = rf_model.estimators_[0]\n",
        "\n",
        "# Plot the tree\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(tree, filled=True, feature_names=eX_train.columns, max_depth=3, precision=2, proportion=True)\n",
        "plt.title('Decision Tree from Random Forest')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3PzxFOIWbTHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear regressionsmodel # 1 sec\n",
        "l_features = ['KM Driven', 'Year', 'Horsepower', 'Km/L', 'Gear_Automatgear', 'Range (Electric)', 'Adaptive Cruise Control']\n",
        "lX_train, lX_test, ly_train, ly_test = train_test_split(e_data[l_features], e_data['Price'], test_size=0.2, random_state=42)\n",
        "\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "linear_model.fit(lX_train, ly_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "linear_predictions = linear_model.predict(lX_test)\n",
        "\n",
        "# Metrics\n",
        "linear_r_squared = r2_score(ly_test, linear_predictions)\n",
        "linear_mae = mean_absolute_error(ly_test, linear_predictions)\n",
        "linear_mse = mean_squared_error(ly_test, linear_predictions)\n",
        "linear_rmse = np.sqrt(linear_mse)\n",
        "\n",
        "print(\"Linear Regression Model Evaluation:\")\n",
        "print(\"R-squared:\", linear_r_squared)\n",
        "print(\"Mean Absolute Error:\", linear_mae)\n",
        "print(\"Mean Squared Error:\", linear_mse)\n",
        "print(\"Root Mean Squared Error:\", linear_rmse)"
      ],
      "metadata": {
        "id": "tNoG90p3bWUn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
